{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from silence_tensorflow import silence_tensorflow\n",
    "silence_tensorflow()\n",
    "\n",
    "import argparse\n",
    "from datetime import date\n",
    "from glob import glob\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n",
    "from augmentor.color import VisualEffect\n",
    "from augmentor.misc import MiscEffect\n",
    "from model import efficientdet\n",
    "from losses import smooth_l1, focal, smooth_l1_quad, iou_loss\n",
    "from efficientnet import BASE_WEIGHTS_PATH, WEIGHTS_HASHES\n",
    "\n",
    "from train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset_type': 'csv', 'detect_quadrangle': False, 'detect_text': False, 'snapshot': 'imagenet', 'freeze_backbone': False, 'freeze_bn': False, 'weighted_bifpn': True, 'lr': 0.0005, 'batch_size': 16, 'phi': 0, 'gpu': '0,1', 'epochs': 200, 'steps': 10000, 'snapshot_path': 'checkpoints/gbb_cat_dog', 'tensorboard_dir': 'logs/2021-04-04', 'snapshots': True, 'evaluation': False, 'random_transform': True, 'compute_val_loss': True, 'loss': 'piou_l3', 'regression_weight': 10.0, 'use_tfrecords': True, 'use_classweights': False, 'freeze_iterations': 0, 'steps_per_epoch': 0, 'multiprocessing': False, 'workers': 1, 'max_queue_size': 10, 'annotations_path': '/datasets/dataset/coco2017/annotations/instances_train2017_obb_cat_dog.csv', 'base_dir_train': '/datasets/dataset/coco2017/train2017', 'classes_path': '/datasets/dataset/coco2017/annotations/classes_cat_dog.csv', 'val_annotations_path': '/datasets/dataset/coco2017/annotations/instances_val2017_obb_cat_dog.csv', 'base_dir_val': '/datasets/dataset/coco2017/val2017'}\n"
     ]
    }
   ],
   "source": [
    "# train all layers\n",
    "args = \"\\\n",
    "--snapshot imagenet \\\n",
    "--snapshot-path checkpoints/gbb_cat_dog \\\n",
    "--loss piou_l3 \\\n",
    "--regression_weight 10 \\\n",
    "--phi 0 \\\n",
    "--weighted-bifpn \\\n",
    "--gpu 0,1 \\\n",
    "--epochs 200 \\\n",
    "--no-evaluation \\\n",
    "--compute-val-loss \\\n",
    "--lr 5e-4 \\\n",
    "--batch-size 16 \\\n",
    "--random-transform \\\n",
    "--use_tfrecords \\\n",
    "csv --annotations_path /datasets/dataset/coco2017/annotations/instances_train2017_obb_cat_dog.csv \\\n",
    "--base_dir_train /datasets/dataset/coco2017/train2017 \\\n",
    "--val_annotations_path /datasets/dataset/coco2017/annotations/instances_val2017_obb_cat_dog.csv \\\n",
    "--base_dir_val /datasets/dataset/coco2017/val2017 \\\n",
    "--classes_path /datasets/dataset/coco2017/annotations/classes_cat_dog.csv\"\n",
    "\n",
    "# parse arguments\n",
    "args = parse_args(args.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optionally choose specific GPU\n",
    "if args.gpu:\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "    \n",
    "if len(tf.config.experimental.list_physical_devices('GPU'))>1:\n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "else:\n",
    "    strategy = tf.distribute.get_strategy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create the generators\n",
    "train_generator, validation_generator = create_generators(args)\n",
    "\n",
    "num_classes = train_generator.num_classes()\n",
    "num_anchors = train_generator.num_anchors\n",
    "\n",
    "# total steps per epoch\n",
    "if args.steps_per_epoch<1:\n",
    "    args.steps_per_epoch = len(train_generator)\n",
    "validation_steps = len(validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if to use tfrecords\n",
    "if args.use_tfrecords:\n",
    "    from generators.tfrecords import create_tfrecords, get_loader\n",
    "    from os.path import exists, join\n",
    "\n",
    "    if args.dataset_type == 'pascal':\n",
    "        data_path = args.pascal_path\n",
    "    elif args.dataset_type == 'coco':\n",
    "        data_path = args.coco_path\n",
    "    elif args.dataset_type =='csv':\n",
    "        data_path = os.path.split(args.base_dir_train)\n",
    "        data_path = os.path.join(*data_path[:-1])\n",
    "    else:\n",
    "        raise Exception('Not implemented yet! Try not using tfrecords option...')\n",
    "    path_tfrecords = os.path.join(data_path, f'tfrecords_cat_dog_phi{args.phi}')\n",
    "    os.makedirs(path_tfrecords, exist_ok=True)\n",
    "\n",
    "    # create tfrecords files\n",
    "    if not glob(join(path_tfrecords, 'train*.tfrec')):\n",
    "        print('Creating tfrecords for train data...')\n",
    "        create_tfrecords(path_tfrecords, 'train', train_generator, repetitions=1)\n",
    "\n",
    "    if not glob(join(path_tfrecords, 'val*.tfrec')):\n",
    "        print('Creating tfrecords for validation data...')\n",
    "        create_tfrecords(path_tfrecords, 'val', validation_generator, repetitions=1)\n",
    "\n",
    "    # get tfrecords loaders\n",
    "    train_generator = get_loader(path_tfrecords, 'train', args.batch_size)\n",
    "    validation_generator = get_loader(path_tfrecords, 'val', args.batch_size)\n",
    "\n",
    "if not args.compute_val_loss:\n",
    "    validation_generator = None\n",
    "elif args.compute_val_loss and validation_generator is None:\n",
    "    raise ValueError('When you have no validation data, you should not specify --compute-val-loss.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    model, prediction_model = efficientdet(args.phi,\n",
    "                                           num_classes=num_classes,\n",
    "                                           num_anchors=num_anchors,\n",
    "                                           weighted_bifpn=args.weighted_bifpn,\n",
    "                                           freeze_bn=args.freeze_bn,\n",
    "                                           detect_quadrangle=args.detect_quadrangle\n",
    "                                           )\n",
    "\n",
    "# load pretrained weights\n",
    "if args.snapshot:\n",
    "    if args.snapshot == 'imagenet':\n",
    "        model_name = 'efficientnet-b{}'.format(args.phi)\n",
    "        file_name = '{}_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5'.format(model_name)\n",
    "        file_hash = WEIGHTS_HASHES[model_name][1]\n",
    "        weights_path = keras.utils.get_file(file_name,\n",
    "                                            BASE_WEIGHTS_PATH + file_name,\n",
    "                                            cache_subdir='models',\n",
    "                                            file_hash=file_hash)\n",
    "        model.load_weights(weights_path, by_name=True)\n",
    "    else:\n",
    "        print('Loading model, this may take a second...')\n",
    "        model.load_weights(args.snapshot)\n",
    "\n",
    "# freeze backbone layers\n",
    "if args.freeze_backbone:\n",
    "    # 227, 329, 329, 374, 464, 566, 656\n",
    "    for i in range(1, [227, 329, 329, 374, 464, 566, 656][args.phi]):\n",
    "        model.layers[i].trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "if args.loss=='l1':\n",
    "    regression_loss = smooth_l1_quad() if args.detect_quadrangle else smooth_l1()\n",
    "else:\n",
    "    regression_loss = iou_loss(mode=args.loss, phi=args.phi,\\\n",
    "                               weight=args.regression_weight,\\\n",
    "                               freeze_iterations=args.freeze_iterations)\n",
    "\n",
    "with strategy.scope():\n",
    "    if 'piou' in args.loss:\n",
    "        optimizer = Adam(lr=args.lr, epsilon=1e-3, decay=1e-4) #, clipvalue=10.\n",
    "    else:\n",
    "        optimizer = Adam(lr=args.lr)\n",
    "    model.compile(optimizer=optimizer, loss={\n",
    "        'regression': regression_loss,\n",
    "        'classification': focal()\n",
    "    }, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "515/515 [==============================] - 239s 321ms/step - loss: 2.4901 - classification_loss: 0.8147 - regression_loss: 1.6753\n",
      "Epoch 2/200\n",
      "515/515 [==============================] - 177s 343ms/step - loss: 0.9070 - classification_loss: 0.2914 - regression_loss: 0.6156\n",
      "Epoch 3/200\n",
      "515/515 [==============================] - 182s 353ms/step - loss: 0.6716 - classification_loss: 0.2149 - regression_loss: 0.4567\n",
      "Epoch 4/200\n",
      "515/515 [==============================] - 182s 353ms/step - loss: 0.5281 - classification_loss: 0.1721 - regression_loss: 0.3560\n",
      "Epoch 5/200\n",
      "515/515 [==============================] - 183s 355ms/step - loss: 0.4312 - classification_loss: 0.1402 - regression_loss: 0.2911\n",
      "Epoch 6/200\n",
      "515/515 [==============================] - 184s 357ms/step - loss: 0.3626 - classification_loss: 0.1152 - regression_loss: 0.2474\n",
      "Epoch 7/200\n",
      "515/515 [==============================] - 184s 356ms/step - loss: 0.3138 - classification_loss: 0.0946 - regression_loss: 0.2191\n",
      "Epoch 8/200\n",
      "495/515 [===========================>..] - ETA: 7s - loss: 0.2810 - classification_loss: 0.0810 - regression_loss: 0.2000"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=args.steps_per_epoch,\n",
    "    epochs=args.epochs,\n",
    "    #callbacks=create_callbacks(\n",
    "    #    model,\n",
    "    #    prediction_model,\n",
    "    #    validation_generator,\n",
    "    #    args,\n",
    "    #),\n",
    "    #validation_data=validation_generator,\n",
    "    #validation_steps=validation_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from utils.anchors import anchors_for_shape\n",
    "from layers import RegressBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BATCH SIZE MUST BE 1\n",
    "i = np.random.randint(0,len(train_generator))\n",
    "x,(y_class, y_regress) = train_generator[i]\n",
    "\n",
    "y_regress.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_regress[...,:-1].max(), y_regress[...,:-1].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes_pred, scores, labels = prediction_model.predict(x)\n",
    "\n",
    "# select those detections\n",
    "boxes_pred = boxes_pred[scores>0.5]\n",
    "\n",
    "boxes_pred.shape, boxes_pred[...,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# post process image\n",
    "image = np.copy(np.squeeze(x))\n",
    "image *= [0.229, 0.224, 0.225]\n",
    "image += [0.485, 0.456, 0.406]\n",
    "image = np.uint8(image*255)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate target and state\n",
    "regression_target = y_regress[:, :, :-1]\n",
    "anchor_state = y_regress[:, :, -1]\n",
    "\n",
    "# convert to boxes values: xmin, ymin, xmax, ymax, angle\n",
    "anchors = train_generator.anchors\n",
    "anchors_input = np.expand_dims(anchors, axis=0)\n",
    "regression_target = RegressBoxes()([anchors_input, regression_target])\n",
    "\n",
    "# filter out \"ignore\" anchors\n",
    "indices = tf.where(keras.backend.equal(anchor_state, 1))\n",
    "boxes_true = tf.gather_nd(regression_target, indices)\n",
    "\n",
    "boxes_true.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(image)\n",
    "current_axis = plt.gca()\n",
    "\n",
    "for b in boxes_true:\n",
    "    xmin, ymin, xmax, ymax, angle = list(map(int, b))\n",
    "    cx = (xmax+xmin)/2; cy = (ymax+ymin)/2\n",
    "    w = (xmax-xmin); h = (ymax-ymin)\n",
    "    \n",
    "    xmin = cx - 1 / 2 * (-h * np.sin(angle) + w * np.cos(angle))\n",
    "    ymin = cy - 1 / 2 * (h * np.cos(angle) + w * np.sin(angle))\n",
    "    \n",
    "    current_axis.add_patch(\n",
    "        plt.Rectangle((xmin, ymin), w, h, angle=angle * 180 / np.pi, color='red', fill=False, linewidth=2)\n",
    "    )\n",
    "    \n",
    "for b in boxes_pred:\n",
    "    xmin, ymin, xmax, ymax, angle = list(map(int, b))\n",
    "    cx = (xmax+xmin)/2; cy = (ymax+ymin)/2\n",
    "    w = (xmax-xmin); h = (ymax-ymin)\n",
    "    \n",
    "    xmin = cx - 1 / 2 * (-h * np.sin(angle) + w * np.cos(angle))\n",
    "    ymin = cy - 1 / 2 * (h * np.cos(angle) + w * np.sin(angle))\n",
    "    \n",
    "    current_axis.add_patch(\n",
    "        plt.Rectangle((xmin, ymin), w, h, angle=angle * 180 / np.pi, color='blue', fill=False, linewidth=2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
